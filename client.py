import os
import streamlit as st
from langserve import RemoteRunnable
import networkx as nx
import plotly.graph_objs as go
import logging
from bili_server.rag_tools.document_loader import DocumentLoader
import xxhash
# è®¾ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)
@st.dialog("Knowledge Graph Stats", width="large")
def show_kg_stats_dialog():
    """Dialog showing detailed knowledge graph statistics and visualization."""
    try:
        # Use the correct filename in dickens directory
        graph_path = "./dickens/graph_chunk_entity_relation.graphml"
        
        if not os.path.exists(graph_path):
            st.markdown("> [!graph] âš  **Knowledge Graph file not found.** Please insert some documents first.")
            return
            
        graph = nx.read_graphml(graph_path)
            
        # Basic stats
        stats = {
            "Nodes": graph.number_of_nodes(),
            "Edges": graph.number_of_edges(),
            "Average Degree": round(sum(dict(graph.degree()).values()) / graph.number_of_nodes(), 2) if graph.number_of_nodes() > 0 else 0
        }
        
        # Display stats with more detail
        st.markdown("## Knowledge Graph Statistics")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Total Nodes", stats["Nodes"])
        with col2:
            st.metric("Total Edges", stats["Edges"])
        with col3:
            st.metric("Average Degree", stats["Average Degree"])
        
        # Add detailed analysis
        st.markdown("## Graph Analysis")
        
        # Calculate additional metrics
        if stats["Nodes"] > 0:
            density = nx.density(graph)
            components = nx.number_connected_components(graph.to_undirected())
            
            st.markdown(f"""
            - **Graph Density:** {density:.4f}
            - **Connected Components:** {components}
            - **Most Connected Nodes:**
            """)
                        
            # Create table headers
            table_lines = [
                "| Node ID | SHA-12 | Connections |",
                "|---------|--------|-------------|"
            ]
            
            # Add rows for top nodes
            degrees = dict(graph.degree())
            top_nodes = sorted(degrees.items(), key=lambda x: x[1], reverse=True)[:5]
            for node, degree in top_nodes:
                # Get first 12 chars of SHA hash
                sha_hash = xxhash.xxh64(node.encode()).hexdigest()[:12]
                table_lines.append(f"| `{node}` | `{sha_hash}` | {degree} |")
            
            # Display the table
            st.markdown("\n".join(table_lines))
        
        # Generate visualization if there are nodes
        if stats["Nodes"] > 0:
            st.markdown("## Knowledge Graph Visualization")
            
            try:
                from pyvis.network import Network
                import random
                
                st.markdown("*Generating interactive network visualization...*")
                
                net = Network(height="600px", width="100%", notebook=True)
                net.from_nx(graph)
                
                # Apply visual styling
                for node in net.nodes:
                    node["color"] = "#{:06x}".format(random.randint(0, 0xFFFFFF))
                
                # Save and display using the same filename pattern
                html_path = "./dickens/graph_chunk_entity_relation.html"
                net.save_graph(html_path)
                
                # Display the saved HTML
                with open(html_path, 'r', encoding='utf-8') as f:
                    html_content = f.read()
                st.components.v1.html(html_content, height=600)
                    
            except ImportError:
                st.markdown("âš ï¸ Please install pyvis to enable graph visualization: `pip install pyvis`")
            except Exception as e:
                st.markdown(f"âŒ **Error generating visualization:** {str(e)}")
        
    except Exception as e:
        logger.error(f"Error getting graph stats: {str(e)}")
        st.markdown(f"âŒ **Error getting graph stats:** {str(e)}")


def show_kg_stats():
    """Show knowledge graph statistics."""
    try:
        rag=DocumentLoader.get_instance().rag
        status_message = ""
        if rag is None:
            status_message = "Knowledge Graph not initialized yet"
            return
            
        graph = rag.chunk_entity_relation_graph._graph
        if graph is None:
            status_message = "Knowledge Graph is empty"
            return
            
        # Calculate stats
        nodes = graph.number_of_nodes()
        edges = graph.number_of_edges()
        avg_degree = round(sum(dict(graph.degree()).values()) / nodes, 2) if nodes > 0 else 0
        
        # Create degree distribution for plotting
        degrees = dict(graph.degree())
        degree_dist = {}
        for d in degrees.values():
            degree_dist[d] = degree_dist.get(d, 0) + 1
            
        # Create plot
        fig = go.Figure(data=[
            go.Bar(x=list(degree_dist.keys()), y=list(degree_dist.values()))
        ])
        fig.update_layout(
            title="Node Degree Distribution",
            xaxis_title="Degree",
            yaxis_title="Count"
        )
        
    #     # Update state with stats and plot
    #     state.kg_stats = {
    #         "nodes": nodes,
    #         "edges": edges,
    #         "avg_degree": avg_degree,
    #         "plot": fig
    #     }
    #     state.show_kg_stats = True
        
    except Exception as e:
        logger.error(f"Error getting graph stats: {str(e)}")
        status_message = f"Error getting graph stats: {str(e)}"

# ä½¿ç”¨ Markdown å’Œæ ·å¼å¢å¼ºæ ‡é¢˜ï¼ŒåŒ…æ‹¬å›¾æ ‡å’Œæ¸å˜è‰²
st.markdown("""
<h1 style='text-align: center; color: blue; background: linear-gradient(to right, red, purple); -webkit-background-clip: text; -webkit-text-fill-color: transparent;'>
      ğŸ“Š BiliBili Search æ£€ç´¢å¢å¼ºåŠ©æ‰‹
</h1>
""", unsafe_allow_html=True)

# åˆ›å»ºä¸€ä¸ªå¤–éƒ¨å®¹å™¨ç”¨äºæ•´ä½“å¸ƒå±€
with st.container():
    # è®¾ç½®è‡ªå®šä¹‰æ ·å¼ä»¥æ§åˆ¶å¸ƒå±€
    st.markdown("""
    <style>
        .search-container {
            display: flex;
            align-items: flex-start; /* å¯¹é½åˆ°é¡¶éƒ¨ */
            gap: 5px; /* ç»„ä»¶ä¹‹é—´çš„é—´è· */
        }
        div[data-baseweb="input"] {
            height: 50px; /* è®¾ç½®è¾“å…¥æ¡†çš„é«˜åº¦ */
            flex-grow: 1; /* è®©è¾“å…¥æ¡†å æ®å‰©ä½™ç©ºé—´ */
        }
        div[data-baseweb="button"] {
            height: 50px; /* ä½¿æŒ‰é’®é«˜åº¦ä¸è¾“å…¥æ¡†ä¸€è‡´ */
        }
        .buttons-column {
            margin-top: 30px; /* å‘ä¸‹ç§»åŠ¨æŒ‰é’®30px */
        }
    </style>
    """, unsafe_allow_html=True)

    # åˆ›å»ºæœç´¢æ¡†å®¹å™¨
    with st.container():
        st.markdown('<div class="search-container">', unsafe_allow_html=True)
        
        col_input, col_search, col_clear = st.columns([4, 0.5, 0.5])  # åˆ†é…æ¯”ä¾‹ç»™å„åˆ—
        with col_input:
            # ä½¿ç”¨ st.empty() åˆ›å»ºä¸€ä¸ªå¯æ›¿æ¢çš„å®¹å™¨
            input_text_container = st.empty()
            # # åœ¨å®¹å™¨ä¸­æ·»åŠ æ–‡æœ¬è¾“å…¥æ¡†
            # input_text = input_text_container.text_input("", placeholder="è¯·è¾“å…¥é—®é¢˜:", key="input")
        with col_search:
            st.markdown('<div class="buttons-column">', unsafe_allow_html=True)
            search_button = st.button("æœç´¢", key="search")
            st.markdown('</div>', unsafe_allow_html=True)  # å…³é—­æŒ‰é’®å®¹å™¨
        with col_clear:
            st.markdown('<div class="buttons-column">', unsafe_allow_html=True)
            clear_button = st.button("æ¸…ç©º", key="clear")
            st.markdown('</div>', unsafe_allow_html=True)  # å…³é—­æŒ‰é’®å®¹å™¨
        
        st.markdown('</div>', unsafe_allow_html=True)  # å…³é—­æœç´¢æ¡†å®¹å™¨

# å¦‚æœç‚¹å‡»äº†æ¸…ç©ºæŒ‰é’®ï¼Œåˆ™æ¸…ç©ºè¾“å…¥æ¡†ä¸­çš„æ–‡æœ¬
if clear_button:
    # ä½¿ç”¨ st.empty() é‡æ–°åˆ›å»ºä¸€ä¸ªç©ºçš„å®¹å™¨ï¼Œæ›¿æ¢åŸæ¥çš„æ–‡æœ¬è¾“å…¥æ¡†
    input_text_container.empty()
    # åœ¨æ–°çš„å®¹å™¨ä¸­æ·»åŠ ä¸€ä¸ªæ–°çš„æ–‡æœ¬è¾“å…¥æ¡†
    input_text = st.text_input("", placeholder="è¯·è¾“å…¥é—®é¢˜:", key="input")
    # æ¸…ç©ºè¾“å…¥æ¡†ä¸­çš„æ–‡æœ¬ï¼Œä½†ä¿ç•™è¾“å…¥æ¡†
    st.session_state.input_text = ""
    # æ‰‹åŠ¨æ›´æ–° input_text å˜é‡çš„å€¼
    input_text = ""

    # # æ˜¾ç¤ºçŸ¥è¯†å›¾è°±æŒ‰é’®å’Œ expander
    # show_knowledge_graph = st.button('æ˜¾ç¤ºçŸ¥è¯†å›¾è°±')

    # if show_knowledge_graph:
    #     with st.sidebar("çŸ¥è¯†å›¾è°±", expanded=True):
    #         show_kg_stats_dialog()


# åˆå§‹åŒ–session stateä¸­çš„å˜é‡ï¼Œå¦‚æœå®ƒè¿˜ä¸å­˜åœ¨çš„è¯
if 'show_kg' not in st.session_state:
    st.session_state.show_kg = False

# æ˜¾ç¤ºæŒ‰é’®ï¼Œå½“ç‚¹å‡»æ—¶æ”¹å˜session stateä¸­çš„show_kgçŠ¶æ€
if st.sidebar.button('æ˜¾ç¤º/éšè— çŸ¥è¯†å›¾è°±'):
    st.session_state.show_kg = not st.session_state.show_kg  # åˆ‡æ¢çŠ¶æ€

# åœ¨ä¾§è¾¹æ ä¸­æ¡ä»¶æ€§åœ°æ˜¾ç¤ºçŸ¥è¯†å›¾è°±
with st.sidebar:
    if st.session_state.show_kg:
        with st.expander("çŸ¥è¯†å›¾è°±", expanded=st.session_state.show_kg):
            st.write("çŸ¥è¯†å›¾è°±åŠ è½½ä¸­......")
            # è°ƒç”¨æ˜¾ç¤ºçŸ¥è¯†å›¾è°±ç»Ÿè®¡å¯¹è¯æ¡†æˆ–ç›¸å…³å†…å®¹çš„å‡½æ•°
            show_kg_stats_dialog()

def show_kg_stats_dialog():
    # è¿™é‡Œæ”¾ç½®å±•ç¤ºçŸ¥è¯†å›¾è°±ç»Ÿè®¡æ•°æ®çš„ä»£ç 
    st.write("è¿™æ˜¯çŸ¥è¯†å›¾è°±çš„ç»Ÿè®¡æ•°æ®å¯¹è¯æ¡†")

# æ³¨æ„ï¼šä½ éœ€è¦è‡ªå·±å®šä¹‰show_kg_stats_dialogå‡½æ•°çš„å…·ä½“å®ç°ã€‚
                

if search_button:
    with st.spinner("æ­£åœ¨å¤„ç†..."):
        try:
            app = RemoteRunnable("http://localhost:8000/biliagent_chat")
            responses = []
            for output in app.stream(input={"input": input_text}, config={"recursion_limit":100}):
                responses.append(output)
                print(output)
            print(responses)
            if responses:
                st.subheader('åˆ†æç»“æœ')
                last_response = responses[-1]
                print(last_response)
                print("--------------")
                if last_response is not None and "generation" in last_response:
                    print(last_response["generation"])
                    st.markdown(last_response["generation"])
                else:
                    st.markdown("No generation data available.")
        except Exception as e:
            st.error(f"å¤„ç†æ—¶å‡ºç°é”™è¯¯: {str(e)}")
            print(last_response["generation"])
            st.markdown(last_response["generation"])